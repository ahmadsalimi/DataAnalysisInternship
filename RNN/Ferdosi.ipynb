{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ferdosi",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdIU2ZBHWFwhMi2JfePMfK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPJ-gN0zmQjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sklearn\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import urllib\n",
        "import random\n",
        "\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abFehw8MmiY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Language:\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            if word != ',' and word != '':\n",
        "                self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHY3pcp4w_jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resource = urllib.request.urlopen(\"https://raw.githubusercontent.com/ahmadsalimi/DataAnalysisInternship/master/RNN/ferdosi.txt\")\n",
        "content = resource.read().decode(resource.headers.get_content_charset())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd1aJSkDy5NP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29b021e1-864d-44b4-bf85-2929389872e2"
      },
      "source": [
        "verses = content.split('\\n')\n",
        "len(verses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49610"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPk7-Rzay7hR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "language = Language('Persian')\n",
        "for verse in verses:\n",
        "    language.addSentence(verse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfOE69p21sdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5040741c-36be-49c1-bfee-008ab20be488"
      },
      "source": [
        "language.n_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17660"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kuagkzL1uwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, lang_size, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            torch.nn.Embedding(lang_size, emb_dim),\n",
        "            torch.nn.Dropout(dropout)\n",
        "        )\n",
        "        \n",
        "        self.rnn = torch.nn.LSTM(emb_dim, enc_hid_dim, num_layers=2)\n",
        "\n",
        "        self.hidden_fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(enc_hid_dim, dec_hid_dim),\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.cell_fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(enc_hid_dim, dec_hid_dim),\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        embedded = self.embedding(src)\n",
        "                \n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        hidden = self.hidden_fc(hidden)\n",
        "        cell = self.cell_fc(cell)\n",
        "        \n",
        "        return outputs, hidden, cell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bt-SMJWV5RO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn = torch.nn.Sequential(\n",
        "            torch.nn.Linear(enc_hid_dim + 2 * dec_hid_dim, dec_hid_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        )\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden            2   B   dec_hid_dim\n",
        "        # encoder_outputs   L   B   enc_hid_dim\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        # encoder_outputs   B   L   enc_hid_dim\n",
        "\n",
        "        #repeat decoder hidden state src_len times\n",
        "        hidden = torch.cat((hidden[0], hidden[1]), dim=1).unsqueeze(1).repeat(1, src_len, 1)\n",
        "        # hidden            B   L   dec_hid_dim*2\n",
        "\n",
        "        return F.softmax(self.attn(torch.cat((encoder_outputs, hidden), dim=2)).squeeze(2), dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2XxIZA1wb1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, lang_size, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            torch.nn.Embedding(lang_size, emb_dim),\n",
        "            torch.nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.rnn = torch.nn.LSTM(emb_dim + enc_hid_dim, dec_hid_dim, num_layers=2)\n",
        "        \n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(emb_dim + enc_hid_dim + dec_hid_dim, lang_size),\n",
        "            torch.nn.LogSoftmax(dim=2)\n",
        "        )\n",
        "    \n",
        "    def forward(self, input, encoder_outputs, hidden, cell):\n",
        "        # input             1   B\n",
        "        # encoder_outputs   L   B   enc_hid_dim\n",
        "        # hidden            2   B   dec_hid_dim\n",
        "        # cell              2   B   dec_hid_dim\n",
        "\n",
        "        embedded = self.embedding(input)\n",
        "        # embedded          1   B   emb_dim\n",
        "\n",
        "        weights = self.attention(hidden, encoder_outputs).unsqueeze(1)\n",
        "        # weights           B   1   L\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        # encoder_outputs   B   L   enc_hid_dim\n",
        "\n",
        "        weighted = torch.bmm(weights, encoder_outputs).permute(1, 0, 2)\n",
        "        # weighted          1   B   enc_hid_dim\n",
        "\n",
        "        lstm_input = torch.cat((embedded, weighted), dim=2)\n",
        "        # lstm_input        1   B   emb_dim + enc_hid_dim\n",
        "\n",
        "        lstm_output, (hidden, cell) = self.rnn(lstm_input, (hidden, cell))\n",
        "        # lstm_output       1   B   dec_hid_dim\n",
        "        # hidden            2   B   dec_hid_dim\n",
        "        # cell              2   B   dec_hid_dim\n",
        "\n",
        "        fc_input = torch.cat((lstm_input, lstm_output), dim=2)\n",
        "        # fc_input          1   B       emb_dim + enc_hid_dim + dec_hid_dim\n",
        "\n",
        "        pred = self.fc(fc_input)\n",
        "        # pred              1   B       lang_size\n",
        "\n",
        "        return pred, hidden, cell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGsjwMsjl5GD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def index_random_choice(p:torch.Tensor):\n",
        "    c = p.cumsum(dim=1).cpu().detach().numpy()\n",
        "    u = np.random.rand(len(c), 1)\n",
        "    return torch.tensor((u < c).argmax(axis=1), device=p.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9XQZcLe7MYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(torch.nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, lang_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.device = device\n",
        "        self.lang_size = lang_size\n",
        "\n",
        "    def forward(self, source, target=None, k=1, teacher_forcing_ratio=0.5, train=True):\n",
        "        # source            L   B\n",
        "        # target            L   B\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(source)\n",
        "        # encoder_outputs   L   B   enc_hid_dim\n",
        "        # hidden            2   B   dec_hid_dim\n",
        "        # cell              2   B   dec_hid_dim\n",
        "\n",
        "        if train:\n",
        "            return self.train_forward(source, target, teacher_forcing_ratio, encoder_outputs, hidden, cell)\n",
        "        return self.kbeams_forward(source, target, k, encoder_outputs, hidden, cell)\n",
        "    \n",
        "    def train_forward(self, source, target, teacher_forcing_ratio, encoder_outputs, hidden, cell):\n",
        "        # source            L   B\n",
        "        # target            L   B\n",
        "\n",
        "        B = source.shape[1]\n",
        "        L = source.shape[0]\n",
        "\n",
        "        outputs = torch.zeros(L, B, self.lang_size).to(self.device)\n",
        "        # outputs           L   B   lang_size\n",
        "\n",
        "        input = torch.tensor([SOS_token] * B, dtype=torch.long, device=self.device)\n",
        "        # input             B\n",
        "\n",
        "        for i in range(1, L):\n",
        "\n",
        "            output, hidden, cell = self.decode(input, encoder_outputs, hidden, cell)\n",
        "            # output        B   lang_size            \n",
        "            # hidden        2   B   dec_hid_dim\n",
        "            # cell          2   B   dec_hid_dim\n",
        "\n",
        "            outputs[i] = output\n",
        "\n",
        "            top = index_random_choice(output)\n",
        "            # top       B\n",
        "\n",
        "            teacher_force = random.random() < teacher_forcing_ratio    \n",
        "\n",
        "            input = target[i] if teacher_force else top\n",
        "        \n",
        "        return outputs\n",
        "\n",
        "    def kbeams_forward(self, source, target, k, encoder_outputs, hidden, cell):\n",
        "        # source            L   B\n",
        "        \n",
        "        B = source.shape[1]\n",
        "        L = source.shape[0]\n",
        "\n",
        "        outputs = torch.zeros(L, B, k, dtype=torch.long).to(self.device)\n",
        "        # outputs           L   B   k\n",
        "        loss = torch.zeros(B, k).to(self.device) if target is not None else None\n",
        "        # loss              B   k\n",
        "\n",
        "        input = torch.tensor([SOS_token] * B, dtype=torch.long, device=self.device)\n",
        "        # input             B\n",
        "\n",
        "        output, hidden, cell = self.decode(input, encoder_outputs, hidden, cell)\n",
        "        # output            B   lang_size            \n",
        "        # hidden            2   B   dec_hid_dim\n",
        "        # cell              2   B   dec_hid_dim\n",
        "\n",
        "        p, indices = output.topk(k=k, dim=1)\n",
        "        # p, indices        B   k\n",
        "\n",
        "        outputs[1] = indices\n",
        "\n",
        "        beam_hidden = hidden.unsqueeze(0).repeat(k, 1, 1, 1)\n",
        "        # beam_hidden       k   2   B   dec_hid_dim\n",
        "        beam_cell = cell.unsqueeze(0).repeat(k, 1, 1, 1)\n",
        "        # cell              k   2   B   dec_hid_dim\n",
        "\n",
        "        beams_p = p\n",
        "        # beams_p           B   k\n",
        "\n",
        "        for i in range(2, L):\n",
        "            candidates_indices = torch.zeros(k, B, k, dtype=torch.long, device=self.device)\n",
        "            candidates_p = torch.zeros(k, B, k, device=self.device)\n",
        "            true_p_per_beam = torch.zeros(B, k, device=self.device) if target is not None else None\n",
        "            \n",
        "            for beam in range(k):\n",
        "                input = outputs[i-1, :, beam]\n",
        "                # input             B\n",
        "\n",
        "                output, hidden, cell = self.decode(input, encoder_outputs, beam_hidden[beam], beam_cell[beam])\n",
        "                # output            B   lang_size      \n",
        "                # hidden            2   B   dec_hid_dim\n",
        "                # cell              2   B   dec_hid_dim\n",
        "\n",
        "                p, indices = output.topk(k=k, dim=1)\n",
        "                # p, indices        B   k\n",
        "\n",
        "                if target is not None:\n",
        "                    true_p_per_beam[:, beam] = output[torch.arange(output.shape[0]), target[i, :]]\n",
        "\n",
        "                candidates_indices[beam] = indices\n",
        "                candidates_p[beam] = p * beams_p[:, beam].unsqueeze(1).repeat(1, k)\n",
        "\n",
        "                beam_hidden[beam] = hidden\n",
        "                beam_cell[beam] = cell\n",
        "            \n",
        "            if target is not None:\n",
        "                loss -= true_p_per_beam\n",
        "            \n",
        "            flatten_p = candidates_p.permute(1, 0, 2).reshape(B, k*k)\n",
        "            # flatten_p             B   k^2\n",
        "\n",
        "            new_p, new_indices = flatten_p.topk(k=k, dim=1)\n",
        "            # new_p, new_indices    B   k\n",
        "\n",
        "            current_word_indices = candidates_indices.permute(1, 0, 2).reshape(B, k*k).gather(dim=1, index=new_indices)\n",
        "            # current_word_indices  B   k\n",
        "\n",
        "            last_beam_indices = (new_indices // k).unsqueeze(0).repeat(L, 1, 1)\n",
        "            # last_beam_indices     L   B   k\n",
        "\n",
        "            outputs = outputs.gather(dim=2, index=last_beam_indices)\n",
        "            outputs[i] = current_word_indices\n",
        "\n",
        "            beams_p = new_p\n",
        "        \n",
        "\n",
        "\n",
        "        best = torch.argmax(beams_p, dim=1).view(-1, 1)\n",
        "        # best                      B   1\n",
        "\n",
        "        outputs = outputs.gather(dim=2, index=best.unsqueeze(0).repeat(L, 1, 1)).flatten(1)\n",
        "\n",
        "        if target is None:\n",
        "            return outputs\n",
        "        \n",
        "        return outputs, torch.mean((loss * 1.0 / L).gather(dim=1, index=best).flatten(0))\n",
        "\n",
        "    def decode(self, input, encoder_outputs, hidden, cell):\n",
        "        # input             B\n",
        "        # encoder_outputs   L   B\n",
        "        # hidden            2   B   dec_hid_dim\n",
        "        # cell              2   B   dec_hid_dim\n",
        "        output, hidden, cell = self.decoder(input.view(1, -1), encoder_outputs, hidden, cell)\n",
        "        return output.squeeze(0), hidden, cell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7uqkJU1Jwc6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0d7c922-c4c0-4639-d72c-571d4a253cea"
      },
      "source": [
        "a = np.random.uniform(size=(B, k))\n",
        "a.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgmJEb_6JTzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c72f3ace-c245-4306-b52c-d328659dc5fc"
      },
      "source": [
        "top = torch.argmax(torch.tensor(a), dim=1).view(-1, 1).unsqueeze(0).repeat(L, 1, 1)\n",
        "top.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF-q3OpvLGJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb645b49-db72-4af0-d91e-ece492ada6ab"
      },
      "source": [
        "total = torch.tensor(np.random.uniform(size=(L, B, k)))\n",
        "total.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttU4wzDNLQ8E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "28f046d7-45bf-4dff-d56a-23cf725eafeb"
      },
      "source": [
        "total.gather(dim=2, index=top).flatten(1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y07thS03GxEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L = 10\n",
        "B = 20\n",
        "k = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSuBozWBkAD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dab06821-797b-41af-edbb-22ab122e3c3d"
      },
      "source": [
        "a = torch.ones(L, B, k)\n",
        "a.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p8TKKALPPoZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "33407af6-790c-4437-a59a-e3d71c983ef0"
      },
      "source": [
        "indices = torch.ones(B, k, dtype=torch.long).unsqueeze(0).repeat(L, 1, 1)\n",
        "indices.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMQsyB9Ou2mR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5d5419d-599f-4858-8bc7-92894a698e9d"
      },
      "source": [
        "indices.gather(dim=2, index=indices).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GeZmK-OkNPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9099d56e-689a-4c3e-f713-77dd73e98de5"
      },
      "source": [
        "a[:].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkWHJ6OrksWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "c24fb283-e76e-4551-bc91-74d640b87cae"
      },
      "source": [
        "i"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[258, 310],\n",
              "        [829, 224],\n",
              "        [820, 589],\n",
              "        [207,  32],\n",
              "        [436, 258],\n",
              "        [442, 144],\n",
              "        [185, 337],\n",
              "        [642, 269],\n",
              "        [285, 321],\n",
              "        [601, 452],\n",
              "        [525,  68],\n",
              "        [662, 699],\n",
              "        [933, 204],\n",
              "        [351,   0],\n",
              "        [315, 742],\n",
              "        [257, 884],\n",
              "        [894, 704],\n",
              "        [527, 259],\n",
              "        [ 32, 522],\n",
              "        [854, 691],\n",
              "        [ 47, 476],\n",
              "        [828, 240],\n",
              "        [721, 274],\n",
              "        [246, 563],\n",
              "        [ 48, 673],\n",
              "        [  1, 795],\n",
              "        [ 99, 646],\n",
              "        [  3, 588],\n",
              "        [418, 274],\n",
              "        [ 58,  81]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evydt1vlk-MK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "44239363-da11-46b9-a563-0eba67ccdb5b"
      },
      "source": [
        "(u < c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False,  True,  True],\n",
              "       [ True,  True,  True],\n",
              "       [False,  True,  True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z97JcBvDlXsv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "56c7e3c5-0fda-40ad-ab4d-e4b02ab62f93"
      },
      "source": [
        "(u < c).argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvo-zm9KQsL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batches = list(get_batches(source_train, target_train, 1, 64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlUacapeRL1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c90ca2b-5de4-4565-de4a-388eb7a7288a"
      },
      "source": [
        "batch_source = batches[0][1]\n",
        "batch_source.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xtz8SidpV85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a5483d85-797a-45b0-b105-ece831040e73"
      },
      "source": [
        "batch_target = batches[0][2]\n",
        "batch_target.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQnaqy6iQihA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(language.n_words, 100, 200, 300, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNM4UziWHBKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention = Attention(200, 300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr0yZWF13AQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder = Decoder(language.n_words, 100, 200, 300, 0.5, attention)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL3YzPn5cFSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq2seq = Seq2Seq(encoder, decoder, device, language.n_words).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoaCB4LmdO8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(seq2seq.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYrBDnW8Cn4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence, max_length):\n",
        "    words = [lang.word2index[word] for word in sentence.split(' ')]\n",
        "    return [SOS_token] + words + [EOS_token] * (max_length - len(words) - 1) \n",
        "\n",
        "def getSentences(lang, sentences, max_length):\n",
        "    sources = []\n",
        "    targets = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if sentence == '':\n",
        "            continue\n",
        "\n",
        "        source, target = sentence.split(',')\n",
        "        sources.append(indexesFromSentence(lang, source.strip(), max_length))\n",
        "        targets.append(indexesFromSentence(lang, target.strip(), max_length))\n",
        "    return torch.tensor(sources, dtype=torch.long).T, torch.tensor(targets, dtype=torch.long).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9X0QMBxh3sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu9qKSnaii3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OG5WzKSgiLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3235f559-12df-43c3-8f88-cb336a9bdc47"
      },
      "source": [
        "sources, targets = getSentences(language, verses, max_length)\n",
        "sources.shape, targets.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([15, 49609]), torch.Size([15, 49609]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67DE0b6b4Nn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_split(X, y, test_size, axis):\n",
        "    indices = torch.tensor(np.random.permutation(X.shape[axis]))\n",
        "    train_indices, test_indices = indices[:int(X.shape[axis] * (1 - test_size))], indices[int(X.shape[axis] * (1 - test_size)):]\n",
        "    return (X.index_select(axis, train_indices),\n",
        "            X.index_select(axis, test_indices),\n",
        "            y.index_select(axis, train_indices),\n",
        "            y.index_select(axis, test_indices))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fpHdEq9gUo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_train, source_test, target_train, target_test = train_test_split(sources, targets, test_size=0.2, axis=1)\n",
        "source_train, source_val, target_train, target_val = train_test_split(source_train, target_train, test_size=0.2, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBeKaeku24aV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4581be02-4c13-4d95-dbeb-c013ad33ca1c"
      },
      "source": [
        "source_train.shape, source_test.shape, source_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([15, 31749]), torch.Size([15, 9922]), torch.Size([15, 7938]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4w4nb54tLQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(source, target, batch_size):\n",
        "    num_batches = int(np.ceil(source.shape[1] * 1.0 / batch_size))\n",
        "\n",
        "    indices = torch.randperm(source.size()[1])\n",
        "\n",
        "    source = source[:, indices]\n",
        "    target = target[:, indices]\n",
        "\n",
        "    for batch in range(num_batches):\n",
        "        yield batch, source[:, batch * batch_size: min((batch + 1) * batch_size, source.shape[1])], target[:, batch * batch_size: min((batch + 1) * batch_size, source.shape[1])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esDvT1gAstUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, source_train, target_train, optimizer, batch_size):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "\n",
        "    i = 0\n",
        "    \n",
        "    for i, b_source, b_target in get_batches(source_train, target_train, batch_size):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(b_source.cuda(), b_target.cuda())\n",
        "        \n",
        "        # b_target      L   B\n",
        "        # pred          L   B   lang_size\n",
        "\n",
        "        b_target = b_target.flatten(0)\n",
        "        pred = pred.view(-1, language.n_words)\n",
        "        \n",
        "        # b_target      L*B\n",
        "        # pred          L*B lang_size\n",
        "\n",
        "        loss = -1 * torch.mean(pred[torch.arange(pred.shape[0]), b_target])        \n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += float(loss)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f'[Train] loss: {epoch_loss / (i + 1):.3e}')\n",
        "        \n",
        "    return epoch_loss / (i + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s6_dCi_xL3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, source_eval, target_eval, batch_size, k):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "\n",
        "    predictions = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, b_source, b_target in get_batches(source_eval, target_eval, batch_size):\n",
        "\n",
        "            pred, loss = model(b_source.cuda(), b_target.cuda(), teacher_forcing_ratio=0, train=True)\n",
        "            # loss          B\n",
        "            # pred          L   B\n",
        "\n",
        "            predictions.append(pred.cpu().numpy())\n",
        "\n",
        "            epoch_loss += float(loss)\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f'[Eval]  loss: {epoch_loss / (i + 1):.3e}')\n",
        "    \n",
        "    return np.concatenate(predictions, axis=1), epoch_loss / (i + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tecBrUIHxuY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0YtN7_FW1s1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "encoder = Encoder(language.n_words, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "decoder = Decoder(language.n_words, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "model = Seq2Seq(encoder, decoder, device, language.n_words).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx1HKEYCyCOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "9771844c-c366-40a5-eb22-35c6fcddb6f2"
      },
      "source": [
        "N_EPOCHS = 40\n",
        "batch_size = 128\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time()\n",
        "    \n",
        "    train_loss = train(model, source_train, target_train, optimizer, batch_size)\n",
        "    _, valid_loss = evaluate(model, source_val, target_val, batch_size, 1)\n",
        "    \n",
        "    end_time = time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'rnn-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3e} | Train PPL: {np.exp(train_loss):.3e}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3e} |  Val. PPL: {np.exp(valid_loss):.3e}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Train] loss: 9.121e+00\n",
            "[Train] loss: 3.433e+00\n",
            "[Train] loss: 3.209e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-946b6e091d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-148-fdf940a0c04b>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, source_eval, target_eval, batch_size, k)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_target\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_source\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;31m# loss          B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# pred          L   B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9khiENOemSqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61e0206b-b08f-4afe-a1b3-de702c62320a"
      },
      "source": [
        "indices = np.random.choice(np.arange(source_test.shape[1]), size=40, replace=False)\n",
        "source = source_test[:, indices]\n",
        "target = target_test[:, indices]\n",
        "pred, valid_loss = evaluate(model, source, target, batch_size, 5)\n",
        "\n",
        "print(pred.shape)\n",
        "\n",
        "for index in range(pred.shape[1]):\n",
        "    print('>', ' '.join(list(map(lambda i: language.index2word[int(i)], source[:, index]))))\n",
        "    print('<', ' '.join(list(map(lambda i: language.index2word[int(i)], pred[:, index]))))\n",
        "    print('=', ' '.join(list(map(lambda i: language.index2word[int(i)], target[:, index]))))\n",
        "    print('-----------------')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Eval]  loss: 3.331e+00\n",
            "(15, 40)\n",
            "> SOS چونامش ز دفتر بخواند دبیر EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همان شاه را همه EOS و EOS را EOS و EOS و EOS بر\n",
            "= SOS برد پیش کودک درم ناگزیر EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS برین امدن رنج برداشتی EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS چنین راه دشوار بگذاشتی EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS سه روز اندران کار شد روزگار EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS که جویند ز ایران یکی شهریار EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS تهمتن به گفتار او شاد شد EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS روانش ز اندیشه ازاد شد EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS چو خسرو بدید ان سپاه نیا EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت با تو و تیمار بود مرد EOS و EOS و EOS بر\n",
            "= SOS دل پادشا شد پر از کیمیا EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS خرامان بیامد به شهر صطخر EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS که شاهنشهان را بدان بود فخر EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS هرانکس که بود از نژاد زرسب EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همان شاه را همه EOS و تخت و EOS و EOS و EOS بر\n",
            "= SOS پذیره شدن را بیاراست اسب EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بسی خواند بر فر او افرین EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS که بی تو مبادا زمان و زمین EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بفرمود تا پرده برداشتند EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS بر اسپش ز درگاه بگذاشتند EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS دل ما به بهرام ازان بود سرد EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS که از شاه بودیم یکسر به درد EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS همی ماند تا جای پردخت شد EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی ریخت از باره برگاشتن اید گزند و EOS و EOS و EOS بر\n",
            "= SOS به نزدیک ان نامور تخت شد EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ز چاه اندر اویختنش سرنگون EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS تنش پر ز خاک و دهن پر ز خون EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ز من خواست پیمان و دادم زمان EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS که هرگز نباشم بدو بدگمان EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS چنان کن که نیک اختر و رای تست EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS که چرخ فلک زیر بالای تست EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ابا پیر دستان که بودش پدر EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS ابا مهتران و گزینان در EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ازن پس عقاب دلاور چهار EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همان شاه را همه EOS و تخت و EOS و EOS و EOS بر\n",
            "= SOS بیاورد و بر تخت بست استوار EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ترا بارگی دادمی ای جوان EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بر و رای زن و کوس و EOS و EOS بر\n",
            "= SOS بدان تات بردی بر پهلوان EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS کنیزک بدان حجره هفتاد بود EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد از تخت EOS و EOS بر EOS بر EOS بر\n",
            "= SOS که هر یک به تن سرو ازاد بود EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS گروگر فرستادم از بهر دین EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS بیارای گفتا به دانش زمین EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS به هرجای پیش وپس اندر سپاه EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS گرازان دو شاه اندران رزمگاه EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS برین سان که گژدهم گوید همی EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS از اندیشه دل را بشوید همی EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ز ما تا بود زنده یک نامدار EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS نپیچیم یک تن سر از کارزار EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS خداوند کیوان و گردان سپهر EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS ز بنده نخواهد بجز داد و مهر EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بکارند و ورزند و خود بدروند EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS به گاه خورش سرزنش نشنوند EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS همه شب همی راند با خود گروه EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همان شاه را همه EOS و EOS را EOS و EOS و EOS بر\n",
            "= SOS چو خورشید تابان برامد ز کوه EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS شما گر خرد را بسیچید کار EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS نه من سیرم از جنگ و از کارزار EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS چودیوار ایوانش امد به جای EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS بیامد به پیش جهان کد خدای EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS هم از گنج ما بی نیازی دهید EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS خردمند را سرفرازی دهید EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ز یزدان بود زور ما خود کییم EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و هم گروه اب EOS و EOS و EOS بر\n",
            "= SOS بدین تیره خاک اندرون بر چییم EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ببردند فرهاد را نزد شاه EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی ریخت از باره برگاشتن اید گزند و EOS را EOS و EOS بر\n",
            "= SOS ز کاووس پرسید و ز رنج راه EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بزد دست و بگرفت پیچان سرش EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS همی خواست کز مار سازد خورش EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ز هر سو هیونی تکاور بتاخت EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی بود و از مردم نیک خوست راه EOS و EOS و EOS بر\n",
            "= SOS سلیح سواران جنگی بساخت EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS چو گفتار پور زره شد ببن EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS سپهدار ایران شنید این سخن EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ندانم که دیدار باشد جزین EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همان شاه را همه EOS و تخت و EOS و EOS و EOS بر\n",
            "= SOS که داند چنین جز جهان افرین EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS به دشمن نمایم هنر هرچ هست EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS ز مردی و پیروزی و زور دست EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS چو بشنید ماهوی بیدادگر EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS سخنها کجا گفت او را پسر EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بدوشاه گفت این چه شاید بدن EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS همه داستانها بباید زدن EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS نباید که گرگ از پسش در کشد EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و با دستوار و EOS نیز EOS و EOS بر\n",
            "= SOS که او را همان بخت خود برکشد EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بپرسید ماهوی زین چاره جوی EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت با تو و تیمار بود مرد EOS و EOS و EOS بر\n",
            "= SOS که برسم کرا خواستی راست گوی EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS زمین را بلندی نبد جایگاه EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی گفت و بد و هم گروه اب EOS و EOS و EOS بر\n",
            "= SOS یکی مرکزی تیره بود و سیاه EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTDUgxuMGUag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def asMinutes(s):\n",
        "    m = np.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6IVYbqSEHbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54YSPPMfEdAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for verse in np.random.choice(verses, size=n):\n",
        "        print('>', verse)\n",
        "        output_words, attentions = evaluate(encoder, decoder, verse)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Da35fZCC_vI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ86i34LFkEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "6710ec27-d769-4cec-fc69-5fe4881ffd09"
      },
      "source": [
        "hidden_size = 256\n",
        "\n",
        "encoder1 = EncoderRNN(language.n_words, hidden_size, device).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, language.n_words, device).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, int(len(verses) * 0.8), print_every=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-e56778337ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-72-22320c4219a6>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtraining_beits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-22320c4219a6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtraining_beits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ1hCdhRH-id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}