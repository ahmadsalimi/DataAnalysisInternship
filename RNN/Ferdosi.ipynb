{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ferdosi",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxeci02tEMqv39lsi/UX1n"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPJ-gN0zmQjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sklearn\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import urllib\n",
        "import random\n",
        "\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abFehw8MmiY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Language:\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            if word != ',' and word != '':\n",
        "                self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHY3pcp4w_jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resource = urllib.request.urlopen(\"https://raw.githubusercontent.com/ahmadsalimi/DataAnalysisInternship/master/RNN/ferdosi.txt\")\n",
        "content = resource.read().decode(resource.headers.get_content_charset())"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd1aJSkDy5NP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef547242-a66f-47e6-c71b-308f1556ecde"
      },
      "source": [
        "verses = content.split('\\n')\n",
        "len(verses)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49610"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPk7-Rzay7hR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "language = Language('Persian')\n",
        "for verse in verses:\n",
        "    language.addSentence(verse)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfOE69p21sdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "757c12d9-e974-4a16-8522-01123f6eb5a5"
      },
      "source": [
        "language.n_words"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17660"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kuagkzL1uwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, lang_size, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            torch.nn.Embedding(lang_size, emb_dim),\n",
        "            torch.nn.Dropout(dropout)\n",
        "        )\n",
        "        \n",
        "        self.rnn = torch.nn.LSTM(emb_dim, enc_hid_dim, num_layers=2)\n",
        "\n",
        "        self.hidden_fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(enc_hid_dim, dec_hid_dim),\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.cell_fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(enc_hid_dim, dec_hid_dim),\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        embedded = self.embedding(src)\n",
        "                \n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        hidden = self.hidden_fc(hidden)\n",
        "        cell = self.cell_fc(cell)\n",
        "        \n",
        "        return outputs, hidden, cell"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bt-SMJWV5RO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn = torch.nn.Sequential(\n",
        "            torch.nn.Linear(enc_hid_dim + 2 * dec_hid_dim, dec_hid_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        )\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden            2   B   dec_hid_dim\n",
        "        # encoder_outputs   L   B   enc_hid_dim\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        # encoder_outputs   B   L   enc_hid_dim\n",
        "\n",
        "        #repeat decoder hidden state src_len times\n",
        "        hidden = torch.cat((hidden[0], hidden[1]), dim=1).unsqueeze(1).repeat(1, src_len, 1)\n",
        "        # hidden            B   L   dec_hid_dim*2\n",
        "\n",
        "        return F.softmax(self.attn(torch.cat((encoder_outputs, hidden), dim=2)).squeeze(2), dim=1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2XxIZA1wb1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, lang_size, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            torch.nn.Embedding(lang_size, emb_dim),\n",
        "            torch.nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.rnn = torch.nn.LSTM(emb_dim + enc_hid_dim, dec_hid_dim, num_layers=2)\n",
        "        \n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(emb_dim + enc_hid_dim + dec_hid_dim, lang_size),\n",
        "            torch.nn.LogSoftmax(dim=2)\n",
        "        )\n",
        "    \n",
        "    def forward(self, input, encoder_outputs, hidden, cell):\n",
        "        # input             1   B\n",
        "        # encoder_outputs   L   B   enc_hid_dim\n",
        "        # hidden            2   B   dec_hid_dim\n",
        "        # cell              2   B   dec_hid_dim\n",
        "\n",
        "        embedded = self.embedding(input)\n",
        "        # embedded          1   B   emb_dim\n",
        "\n",
        "        weights = self.attention(hidden, encoder_outputs).unsqueeze(1)\n",
        "        # weights           B   1   L\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        # encoder_outputs   B   L   enc_hid_dim\n",
        "\n",
        "        weighted = torch.bmm(weights, encoder_outputs).permute(1, 0, 2)\n",
        "        # weighted          1   B   enc_hid_dim\n",
        "\n",
        "        lstm_input = torch.cat((embedded, weighted), dim=2)\n",
        "        # lstm_input        1   B   emb_dim + enc_hid_dim\n",
        "\n",
        "        lstm_output, (hidden, cell) = self.rnn(lstm_input, (hidden, cell))\n",
        "        # lstm_output       1   B   dec_hid_dim\n",
        "        # hidden            2   B   dec_hid_dim\n",
        "        # cell              2   B   dec_hid_dim\n",
        "\n",
        "        fc_input = torch.cat((lstm_input, lstm_output), dim=2)\n",
        "        # fc_input          1   B       emb_dim + enc_hid_dim + dec_hid_dim\n",
        "\n",
        "        pred = self.fc(fc_input)\n",
        "        # pred              1   B       lang_size\n",
        "\n",
        "        return pred, hidden, cell"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGsjwMsjl5GD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def index_random_choice(p:torch.Tensor):\n",
        "    c = p.cumsum(dim=1).cpu().detach().numpy()\n",
        "    u = np.random.rand(len(c), 1)\n",
        "    return torch.tensor((u < c).argmax(axis=1), device=p.device)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9XQZcLe7MYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(torch.nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, lang_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.device = device\n",
        "        self.lang_size = lang_size\n",
        "\n",
        "    def forward(self, source, target=None, k=1, teacher_forcing_ratio=0.5, train=True):\n",
        "        # source            L   B\n",
        "        # target            L   B\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(source)\n",
        "        # encoder_outputs   L   B   enc_hid_dim\n",
        "        # hidden            2   B   dec_hid_dim\n",
        "        # cell              2   B   dec_hid_dim\n",
        "\n",
        "        if train:\n",
        "            return self.train_forward(source, target, teacher_forcing_ratio, encoder_outputs, hidden, cell)\n",
        "        return self.kbeams_forward(source, k, encoder_outputs, hidden, cell)\n",
        "    \n",
        "    def train_forward(self, source, target, teacher_forcing_ratio, encoder_outputs, hidden, cell):\n",
        "        # source            L   B\n",
        "        # target            L   B\n",
        "\n",
        "        B = source.shape[1]\n",
        "        L = source.shape[0]\n",
        "\n",
        "        outputs = torch.zeros(L, B, self.lang_size).to(self.device)\n",
        "        # outputs           L   B   lang_size\n",
        "\n",
        "        input = torch.tensor([SOS_token] * B, dtype=torch.long, device=self.device)\n",
        "        # input             B\n",
        "\n",
        "        for i in range(1, L):\n",
        "\n",
        "            output, hidden, cell = self.decode(input, encoder_outputs, hidden, cell)\n",
        "            # output        B   lang_size            \n",
        "            # hidden        2   B   dec_hid_dim\n",
        "            # cell          2   B   dec_hid_dim\n",
        "\n",
        "            outputs[i] = output\n",
        "\n",
        "            top = index_random_choice(output)\n",
        "            # top       B\n",
        "\n",
        "            teacher_force = random.random() < teacher_forcing_ratio    \n",
        "\n",
        "            input = target[i] if teacher_force else top\n",
        "        \n",
        "        return outputs\n",
        "\n",
        "    def kbeams_forward(self, source, k, encoder_outputs, hidden, cell):\n",
        "        # source            L   B\n",
        "        \n",
        "        B = source.shape[1]\n",
        "        L = source.shape[0]\n",
        "\n",
        "        outputs = torch.zeros(L, B, k).to(self.device)\n",
        "        # outputs           L   B   k\n",
        "\n",
        "        temp_k = 1\n",
        "\n",
        "        input = torch.tensor([SOS_token] * B, dtype=torch.long, device=self.device)\n",
        "        # input             B\n",
        "\n",
        "        output, hidden, cell = self.decode(input, encoder_outputs, hidden, cell)\n",
        "        # output            B   lang_size            \n",
        "        # hidden            2   B   dec_hid_dim\n",
        "        # cell              2   B   dec_hid_dim\n",
        "\n",
        "        p, indices = output.topk(k=k, dim=1)\n",
        "        # p, indices        B   k\n",
        "\n",
        "        outputs[1] = indices\n",
        "\n",
        "        beam_hidden = hidden.unsqueeze(0).repeat(k, 1, 1, 1)\n",
        "        # beam_hidden       k   2   B   dec_hid_dim\n",
        "        beam_cell = cell.unsqueeze(0).repeat(k, 1, 1, 1)\n",
        "        # cell              k   2   B   dec_hid_dim\n",
        "\n",
        "        beams_p = p\n",
        "        # beams_p           B   k\n",
        "\n",
        "        for i in range(2, L):\n",
        "            candidates_indices = np.zeros(k, B, k)\n",
        "            candidates_p = np.zeros(k, B, k)\n",
        "            \n",
        "            for beam in range(k):\n",
        "                input = outputs[i-1, :, beam]\n",
        "                # input             B\n",
        "\n",
        "                output, hidden, cell = self.decode(input, encoder_outputs, beam_hidden[beam], beam_cell[beam])\n",
        "                # output            B   lang_size      \n",
        "                # hidden            2   B   dec_hid_dim\n",
        "                # cell              2   B   dec_hid_dim\n",
        "\n",
        "                p, indices = output.topk(k=k, dim=1)\n",
        "                # p, indices        B   k\n",
        "\n",
        "                candidates_indices[beam] = indices\n",
        "                candidates_p[beam] = p * beams_p[:, beam].unsqueeze(1).repeat(k)\n",
        "\n",
        "                beam_hidden[beam] = hidden\n",
        "                beam_cell[beam] = cell\n",
        "            \n",
        "            flatten_p = candidates_p.permute(1, 0, 2).view(B, -1)\n",
        "            # flatten_p             B   k^2\n",
        "\n",
        "            new_p, new_indices = flatten_p.topk(k=k, dim=1)\n",
        "            # new_p, new_indices    B   k\n",
        "\n",
        "            current_word_indices = candidates_indices.permute(1, 0, 2).view(B, -1)[new_indices]\n",
        "            # current_word_indices  B   k\n",
        "\n",
        "            last_beam_indices = (new_indices // k).unsqueeze(0).repeat(L, 1, 1)\n",
        "            # last_beam_indices     L   B   k\n",
        "\n",
        "            outputs = outputs.gather(dim=2, index=last_beam_indices)\n",
        "            outputs[i] = current_word_indices\n",
        "\n",
        "            beams_p = new_p\n",
        "        \n",
        "        return outputs\n",
        "\n",
        "    def decode(self, input, encoder_outputs, hidden, cell):\n",
        "        # input             B\n",
        "        # encoder_outputs   L   B\n",
        "        # hidden            2   B   dec_hid_dim\n",
        "        # cell              2   B   dec_hid_dim\n",
        "        output, hidden, cell = self.decoder(input.view(1, -1), encoder_outputs, hidden, cell)\n",
        "        return output.squeeze(0), hidden, cell"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y07thS03GxEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L = 10\n",
        "B = 20\n",
        "k = 5"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSuBozWBkAD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dab06821-797b-41af-edbb-22ab122e3c3d"
      },
      "source": [
        "a = torch.ones(L, B, k)\n",
        "a.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p8TKKALPPoZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "33407af6-790c-4437-a59a-e3d71c983ef0"
      },
      "source": [
        "indices = torch.ones(B, k, dtype=torch.long).unsqueeze(0).repeat(L, 1, 1)\n",
        "indices.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMQsyB9Ou2mR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5d5419d-599f-4858-8bc7-92894a698e9d"
      },
      "source": [
        "indices.gather(dim=2, index=indices).shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GeZmK-OkNPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9099d56e-689a-4c3e-f713-77dd73e98de5"
      },
      "source": [
        "a[:].shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkWHJ6OrksWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "c24fb283-e76e-4551-bc91-74d640b87cae"
      },
      "source": [
        "i"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[258, 310],\n",
              "        [829, 224],\n",
              "        [820, 589],\n",
              "        [207,  32],\n",
              "        [436, 258],\n",
              "        [442, 144],\n",
              "        [185, 337],\n",
              "        [642, 269],\n",
              "        [285, 321],\n",
              "        [601, 452],\n",
              "        [525,  68],\n",
              "        [662, 699],\n",
              "        [933, 204],\n",
              "        [351,   0],\n",
              "        [315, 742],\n",
              "        [257, 884],\n",
              "        [894, 704],\n",
              "        [527, 259],\n",
              "        [ 32, 522],\n",
              "        [854, 691],\n",
              "        [ 47, 476],\n",
              "        [828, 240],\n",
              "        [721, 274],\n",
              "        [246, 563],\n",
              "        [ 48, 673],\n",
              "        [  1, 795],\n",
              "        [ 99, 646],\n",
              "        [  3, 588],\n",
              "        [418, 274],\n",
              "        [ 58,  81]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evydt1vlk-MK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "44239363-da11-46b9-a563-0eba67ccdb5b"
      },
      "source": [
        "(u < c)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False,  True,  True],\n",
              "       [ True,  True,  True],\n",
              "       [False,  True,  True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z97JcBvDlXsv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "56c7e3c5-0fda-40ad-ab4d-e4b02ab62f93"
      },
      "source": [
        "(u < c).argmax(axis=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvo-zm9KQsL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batches = list(get_batches(source_train, target_train, 1, 64))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlUacapeRL1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c90ca2b-5de4-4565-de4a-388eb7a7288a"
      },
      "source": [
        "batch_source = batches[0][1]\n",
        "batch_source.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xtz8SidpV85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a5483d85-797a-45b0-b105-ece831040e73"
      },
      "source": [
        "batch_target = batches[0][2]\n",
        "batch_target.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQnaqy6iQihA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(language.n_words, 100, 200, 300, 0.5)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNM4UziWHBKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention = Attention(200, 300)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr0yZWF13AQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder = Decoder(language.n_words, 100, 200, 300, 0.5, attention)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL3YzPn5cFSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq2seq = Seq2Seq(encoder, decoder, device, language.n_words).cuda()"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoaCB4LmdO8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(seq2seq.parameters())"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYrBDnW8Cn4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence, max_length):\n",
        "    words = [lang.word2index[word] for word in sentence.split(' ')]\n",
        "    return [SOS_token] + words + [EOS_token] * (max_length - len(words) - 1) \n",
        "\n",
        "def getSentences(lang, sentences, max_length):\n",
        "    sources = []\n",
        "    targets = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if sentence == '':\n",
        "            continue\n",
        "\n",
        "        source, target = sentence.split(',')\n",
        "        sources.append(indexesFromSentence(lang, source.strip(), max_length))\n",
        "        targets.append(indexesFromSentence(lang, target.strip(), max_length))\n",
        "    return torch.tensor(sources, dtype=torch.long).T, torch.tensor(targets, dtype=torch.long).T"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9X0QMBxh3sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu9qKSnaii3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = 15"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OG5WzKSgiLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb6031fe-93e6-4d78-8429-f20b4cdaaa5b"
      },
      "source": [
        "sources, targets = getSentences(language, verses, max_length)\n",
        "sources.shape, targets.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([15, 49609]), torch.Size([15, 49609]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67DE0b6b4Nn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_split(X, y, test_size, axis):\n",
        "    indices = torch.tensor(np.random.permutation(X.shape[axis]))\n",
        "    train_indices, test_indices = indices[:int(X.shape[axis] * (1 - test_size))], indices[int(X.shape[axis] * (1 - test_size)):]\n",
        "    return (X.index_select(axis, train_indices),\n",
        "            X.index_select(axis, test_indices),\n",
        "            y.index_select(axis, train_indices),\n",
        "            y.index_select(axis, test_indices))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fpHdEq9gUo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_train, source_test, target_train, target_test = train_test_split(sources, targets, test_size=0.2, axis=1)\n",
        "source_train, source_val, target_train, target_val = train_test_split(source_train, target_train, test_size=0.2, axis=1)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBeKaeku24aV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f9c52f61-4bda-4ae6-f69c-a277aa70195d"
      },
      "source": [
        "source_train.shape, source_test.shape, source_val.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([15, 31749]), torch.Size([15, 9922]), torch.Size([15, 7938]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0YtN7_FW1s1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "encoder = Encoder(language.n_words, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "decoder = Decoder(language.n_words, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "model = Seq2Seq(encoder, decoder, device, language.n_words).to(device)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmKAGqFdnlcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4w4nb54tLQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(source, target, axis, batch_size):\n",
        "    num_batches = int(np.ceil(source.shape[axis] * 1.0 / batch_size))\n",
        "\n",
        "    for batch in range(num_batches):\n",
        "        yield batch, source[:, batch * batch_size: min((batch + 1) * batch_size, source.shape[axis])], target[:, batch * batch_size: min((batch + 1) * batch_size, source.shape[axis])]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esDvT1gAstUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, source_train, target_train, optimizer, batch_size):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "\n",
        "    i = 0\n",
        "    \n",
        "    for i, b_source, b_target in get_batches(source_train, target_train, 1, batch_size):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(b_source.cuda(), b_target.cuda())\n",
        "        \n",
        "        # b_target      L   B\n",
        "        # pred          L   B   lang_size\n",
        "\n",
        "        b_target = b_target.flatten(0)\n",
        "        pred = pred.view(-1, language.n_words)\n",
        "        \n",
        "        # b_target      L*B\n",
        "        # pred          L*B lang_size\n",
        "\n",
        "        loss = -1 * torch.mean(pred[torch.arange(pred.shape[0]), b_target])        \n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += float(loss)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f'[Train] loss: {epoch_loss / (i + 1):.3e}')\n",
        "        \n",
        "    return epoch_loss / (i + 1)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s6_dCi_xL3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, source_eval, target_eval, batch_size, k):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "\n",
        "    predictions = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, b_source, b_target in get_batches(source_eval, target_eval, 1, batch_size):\n",
        "\n",
        "            pred = model(b_source.cuda(), k=k, teacher_forcing_ratio=0, train=False)\n",
        "            \n",
        "            # b_target      L   B\n",
        "            # pred          L   B   k\n",
        "\n",
        "            b_target = b_target.unsqueeze(2).repeat(1, 1, k).flatten(0)\n",
        "            flat_pred = pred.flatten(0)\n",
        "            \n",
        "            predictions.append(pred.cpu().numpy())\n",
        "\n",
        "            # b_target      L * B * k\n",
        "            # flat_pred     L * B * k\n",
        "\n",
        "            loss = -1 * torch.mean(flat_pred[torch.arange(flat_pred.shape[0]), b_target])        \n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f'[Eval]  loss: {epoch_loss / (i + 1):.3e}')\n",
        "        \n",
        "    return np.concatenate(np.concatenate(predictions, axis=1), axis=1), epoch_loss / (i + 1)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tecBrUIHxuY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx1HKEYCyCOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e9fc69bb-5519-49fc-e9e7-b3cc9d482a10"
      },
      "source": [
        "N_EPOCHS = 2\n",
        "batch_size = 128\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time()\n",
        "    \n",
        "    train_loss = train(model, source_train, target_train, optimizer, batch_size)\n",
        "    _, valid_loss = evaluate(model, source_val, target_val, batch_size, 5)\n",
        "    \n",
        "    end_time = time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'rnn-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3e} | Train PPL: {np.exp(train_loss):.3e}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3e} |  Val. PPL: {np.exp(valid_loss):.3e}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Train] loss: 9.239e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9khiENOemSqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "933e6903-b80c-45da-8989-9618d57f05e9"
      },
      "source": [
        "indices = np.random.choice(np.arange(source_test.shape[1]), size=40, replace=False)\n",
        "source = source_test[:, indices]\n",
        "target = target_test[:, indices]\n",
        "pred, valid_loss = evaluate(model, source, target, batch_size)\n",
        "\n",
        "print(pred.shape)\n",
        "\n",
        "for index in range(pred.shape[1]):\n",
        "    print('>', ' '.join(list(map(lambda i: language.index2word[int(i)], source[:, index]))))\n",
        "    print('<', ' '.join(list(map(lambda i: language.index2word[int(i)], pred[:, index]))))\n",
        "    print('=', ' '.join(list(map(lambda i: language.index2word[int(i)], target[:, index]))))\n",
        "    print('-----------------')\n",
        "\n"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Eval]  loss: 2.808e+00\n",
            "(15, 40)\n",
            "> SOS بماند سخن چین ودوروی دیو EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که از و غریو غریو EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS بریده دل از بیم کیهان خدیو EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS که از من پس از مرگ ماند نشان EOS EOS EOS EOS EOS EOS\n",
            "< SOS به از از گردنکشان گردنکشان EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS ز گنج شهنشاه گردنکشان EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بد اندیش یاران او را براند EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS به پیش درشگفتی او براند EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS جز از شاه و پیروز خسرو نماند EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS برانم که او را سوی خان خویش EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS به شمع با او و خویش خویش EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS برم تا بدارمش چون جان خویش EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS چو گاو از سر کوه بنداختند EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS ز لشکر روستا و EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS بران اژدها دل بپرداختند EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS دگر ده شتر بار کرد از درم EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که میخ و بیش و بیش و کم EOS EOS EOS EOS EOS EOS\n",
            "= SOS چو باشد درم دل نباشد به غم EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS غنیمت همه بهر لشکر نهاد EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS به کشمر نگر تا چه مادر نزاد EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS نیامدش از اگندن گنج باد EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS شما را سوی پارس باید شدن EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS بیفروختی به زدن زدن EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS شبستان بیاوردن و امدن EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بفرمود تا رفت پیش اورمزد EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS به کشتی و شهریاران و EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS بدو گفت کای چون گل اندر فرزد EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS چو تنها به دیدش زن چاره جوی EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS بتابد ز پیغام دل از روی EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS از ان مغفر تیره بگشاد روی EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بپرسید شاه ازبن و از نژاد EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS ز کاوس و و کرد یاد EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS ز تیزی و ارام و فرهنگ و داد EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS نباشد مرا با تو زین بیش جنگ EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS نباید که کار تنگ کار تنگ EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS ببینی کنون روز تاریک و تنگ EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS همه شب همی لشکر اراستند EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS به نخچیر برفگنده پهلوان خواستند EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS همی جوشن و تیغ پیراستند EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS به درویش بخشید گنج درم EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS به درین هرجای و دژم EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS نماند اندران بوم و برکس دژم EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بر اید رخ کوه رخشان کند EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS بکوشد که ز دل کند کند EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS زمین چون نگین بدخشان کند EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS نه این بود پیمانت با مادرم EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که از و و شود EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS نگفتی که از راستی نگذرم EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بفرمود تا بر در گنبدش EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS بتابند با او و EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS بدادند جاماسپ را موبدش EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS همی گفت اگر بر سرم کردگار EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS تویی از گردش روزگار EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS نوشتست مردن ببد روزگار EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS چو امد بنزدیک اب زره EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS ز و جادویها و EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS گشادند گردان میان از گره EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS همه بوم اباد و فرزند وگنج EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS اگر چند و و و EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS بمانیم و با تو گزینیم رنج EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS زبانها پر از افرین تو باد EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS سر اختر و شکار تو باد EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS سر چرخ گردان زمین تو باد EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بدو گفت اگر نزد شاهم بری EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که بربر بفرمان و EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS بیابی ز من تاج و انگشتری EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ز گیتی خور و بخش و پیمان مراست EOS EOS EOS EOS EOS EOS\n",
            "< SOS همان جامه و حزم و ملخ EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS بزرگی و شاهی و فرمان مراست EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS به پدرود کردن رخ هر کسی EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که از بهرش بسی بسی بسی EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS ببوسم ببارم ز مژگان بسی EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS پر از مرد دانا بود دامنش EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که از و پیوسته و EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS پر از خوب رخ جیب پیراهنش EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS میان سپه کاویانی درفش EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS گشادند شد از تیغهای بنفش بنفش EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS بپیش اندرون تیغهای بنفش EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS کند با سپاهش پس اهنگ اوی EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که ان باد و و اوی اوی EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS نهاده دلش نیز بر جنگ اوی EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS یکی را برهنه سروپای و سفت EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS ز با با مان و جای EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS نه ارام و خواب و نه جای نهفت EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS نه از تخمه ویسه ماند کسی EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که از جهان بخش بسی بسی EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS که اندر سرش مغز باشد بسی EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS سر پادشاهیش را کس ندید EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که بگذاشتی را به EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS نشد خوار هرکس که او را گزید EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ولیکن چو پیمان چنین بد نخست EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که گویم ترا بی نیارند نیارند EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS بهانه نشاید به بیداد جست EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS وزین جا سوی زابلستان شود EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS ز دشمن هراسان شود شود لاغر شود EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS برایین خسروپرستان شود EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS چو افگند سیمرغ بر زال مهر EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS دگرگونه کودک امد به چهر چهر EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS برو گشت زین گونه چندی سپهر EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS همانگه سرش را ز تن دور کن EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS به پایش به کامران سور کن EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS ازو کرگسان را یکی سور کن EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ز لشکر نیا را همی جست شاه EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS همی کرد افریدون سنگ به راه EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS بیامد دمان تا بقلب سپاه EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS بدل گفت خیره بیازردمش EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که از تو را به EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS چرا خواسته پیش ناوردمش EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS همه موبدان را بر خویش خواند EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS بیراست و بخوردن و با او براند EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS شنیده سخن پیش ایشان براند EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS سخن هرچ گفتم بجای اورم EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که نزدیک او را اورم EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS خرد پیش تو رهنمای اورم EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS ازو یک زمان شیروشهدست بهر EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS که زهر تریاک زهر زهر EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS به دیگر زمان چون گزاینده زهر EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n",
            "> SOS برادر نداری نه خواهر نه زن EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "< SOS به خوبی و انجمن انجمن EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "= SOS چو شاخ گلی بر کنار چمن EOS EOS EOS EOS EOS EOS EOS EOS\n",
            "-----------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTDUgxuMGUag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def asMinutes(s):\n",
        "    m = np.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6IVYbqSEHbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54YSPPMfEdAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for verse in np.random.choice(verses, size=n):\n",
        "        print('>', verse)\n",
        "        output_words, attentions = evaluate(encoder, decoder, verse)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Da35fZCC_vI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ86i34LFkEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "6710ec27-d769-4cec-fc69-5fe4881ffd09"
      },
      "source": [
        "hidden_size = 256\n",
        "\n",
        "encoder1 = EncoderRNN(language.n_words, hidden_size, device).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, language.n_words, device).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, int(len(verses) * 0.8), print_every=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-e56778337ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-72-22320c4219a6>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtraining_beits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-22320c4219a6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtraining_beits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ1hCdhRH-id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}