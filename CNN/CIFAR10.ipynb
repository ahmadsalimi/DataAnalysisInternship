{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMB9h5z+5fSeb2vjNnpWFCD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9j6XomVyKDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27pX20yJ1D3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Cifar10Classifier(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Cifar10Classifier, self).__init__()\n",
        "\n",
        "        self.features = torch.nn.Sequential(                                                        # inp: B 3 32 32\n",
        "            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),    # B 32 32 32\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),   # B 32 32 32\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0),                                 # B 32 16 16\n",
        "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),   # B 64 16 16\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),   # B 64 16 16\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0),                                 # B 64 8 8\n",
        "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),  # B 128 8 8\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1), # B 128 8 8\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)                                  # B 128 4 4\n",
        "        )\n",
        "\n",
        "        self.decider = torch.nn.Sequential(\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(4 * 4 * 128, 128),                                                      # B 128\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 10)                                                                # B 10\n",
        "        )\n",
        "\n",
        "        self.log_prob_cal = torch.nn.LogSoftmax(dim=-1)\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(filter(\n",
        "            lambda p: p.requires_grad, self.parameters()), \n",
        "            lr=0.001\n",
        "        )\n",
        "\n",
        "        self.batch_x_placeholder = torch.zeros(size=[1, 3, 32, 32], dtype=torch.float32, device=torch.device('cuda:0'))\n",
        "        self.batch_y_placeholder = torch.zeros(size=[1], dtype=torch.long, device=torch.device('cuda:0'))\n",
        "    \n",
        "    def forward(self, b_x, b_y=None):\n",
        "        conv_features = self.features(b_x)\n",
        "        class_scores = self.decider(conv_features.flatten(1))\n",
        "        log_probs = self.log_prob_cal(class_scores)\n",
        "        loss = -1 * torch.mean(log_probs[torch.arange(b_x.shape[0]), b_y])\n",
        "        decision = torch.argmax(log_probs, dim=-1)\n",
        "        return decision, loss\n",
        "    \n",
        "    def train_epoch(self, X_train, y_train, batch_size):\n",
        "        self.train()\n",
        "\n",
        "        iters_per_epoch = int(np.ceil(1.0 * len(X_train) / batch_size))\n",
        "\n",
        "        # shuffling\n",
        "        indices = np.arange(len(X_train))\n",
        "\n",
        "        epoch_loss = 0\n",
        "        tps = 0\n",
        "\n",
        "        # iterate over training set\n",
        "        for iter in range(iters_per_epoch):\n",
        "            batch_indices = indices[iter * batch_size: min(len(indices), (iter + 1) * batch_size)]\n",
        "\n",
        "            # reshape placeholder\n",
        "            if len(batch_indices) != len(self.batch_x_placeholder):\n",
        "                self.batch_x_placeholder.resize_([len(batch_indices), 3, 32, 32])\n",
        "                self.batch_y_placeholder.resize_([len(batch_indices), 1])\n",
        "\n",
        "            self.batch_x_placeholder.copy_(torch.Tensor(X_train[batch_indices, :, :, :]))\n",
        "            self.batch_y_placeholder.copy_(torch.Tensor(y_train[batch_indices].astype(int)))\n",
        "\n",
        "            b_decision, b_loss = self(self.batch_x_placeholder, self.batch_y_placeholder)\n",
        "            b_decision = b_decision.cpu().numpy()\n",
        "\n",
        "            epoch_loss += float(b_loss) / iters_per_epoch\n",
        "            tps += np.sum(y_train[batch_indices].astype(int) == b_decision)\n",
        "\n",
        "            b_loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "            \n",
        "        epoch_train_accuracy = tps * 100.0 / len(X_train)\n",
        "\n",
        "        return epoch_loss, epoch_train_accuracy\n",
        "    \n",
        "    def evaluate(self, X, y, batch_size):\n",
        "        with torch.no_grad():\n",
        "            self.eval()\n",
        "\n",
        "            iters_per_epoch = int(np.ceil(1.0 * len(X) / batch_size))\n",
        "\n",
        "            indices = np.arange(len(X))\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "            loss = 0\n",
        "            tps = 0\n",
        "\n",
        "            for iter in range(iters_per_epoch):\n",
        "                batch_indices = indices[iter * batch_size: min(len(indices), (iter + 1) * batch_size)]\n",
        "\n",
        "                # reshape placeholder\n",
        "                if len(batch_indices) != len(self.batch_x_placeholder):\n",
        "                    self.batch_x_placeholder.resize_([len(batch_indices), 3, 32, 32])\n",
        "                    self.batch_y_placeholder.resize_([len(batch_indices), 1])\n",
        "                    \n",
        "                self.batch_x_placeholder.copy_(torch.Tensor(X[batch_indices]))\n",
        "                self.batch_y_placeholder.copy_(torch.Tensor(y[batch_indices].astype(int)))\n",
        "\n",
        "                b_decision, b_loss = self(self.batch_x_placeholder, self.batch_y_placeholder)\n",
        "                b_decision = b_decision.cpu().numpy()\n",
        "\n",
        "                loss += float(b_loss) / iters_per_epoch\n",
        "                tps += np.sum(y[batch_indices].astype(int) == b_decision)\n",
        "\n",
        "            accuracy = tps * 100.0 / len(X)\n",
        "\n",
        "            return loss, accuracy\n",
        "\n",
        "    def fit(self, X_train, y_train, epochs, batch_size):\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=40)\n",
        "\n",
        "        train_loss = np.zeros((epochs,))\n",
        "        val_loss = np.zeros((epochs,))\n",
        "        train_acc = np.zeros((epochs,))\n",
        "        val_acc = np.zeros((epochs,))\n",
        "\n",
        "        val_iters_per_epoch = int(np.ceil(1.0 * len(X_val) / batch_size))\n",
        "\n",
        "        for e in range(epochs):\n",
        "            t_start = time()\n",
        "\n",
        "            # train over dataset\n",
        "            epoch_train_loss, epoch_train_accuracy = self.train_epoch(X_train, y_train, batch_size)\n",
        "            train_loss[e] = epoch_train_loss\n",
        "            train_acc[e] = epoch_train_accuracy\n",
        "\n",
        "            # validating over validation set\n",
        "            epoch_val_loss, epoch_val_accuracy = self.evaluate(X_val, y_val, batch_size)\n",
        "            val_loss[e] = epoch_val_loss\n",
        "            val_acc[e] = epoch_val_accuracy\n",
        "\n",
        "            #saving model\n",
        "            torch.save({\n",
        "                    'epoch': e,\n",
        "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                    'model_state_dict': self.state_dict(),\n",
        "                    'epoch_train_loss': epoch_train_loss,\n",
        "                    'epoch_train_accuracy': epoch_train_accuracy,\n",
        "                    'epoch_val_loss': epoch_val_loss,\n",
        "                    'epoch_val_accuracy': epoch_val_accuracy\n",
        "                }, f'CIFAR10/epoch_{e}_state.pt')\n",
        "\n",
        "            print(f'Epoch {e} finished in {time() - t_start:.2f}s. loss: {epoch_train_loss:.4f} - acc: {epoch_train_accuracy:.2f} - val loss: {epoch_val_loss:.4f} - val acc: {epoch_val_accuracy:.2f}')\n",
        "        \n",
        "        return train_loss, val_loss, train_acc, val_acc"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkfIuaoL-hee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUXFc6mMvD10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "55b48d12-0972-4891-b66c-eebbf82829e8"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOyZBqH8tMqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d76aea8-34f3-4f5c-824f-f9b1640cdaaf"
      },
      "source": [
        "X_train = np.transpose(X_train, axes=(0, 3, 1, 2))\n",
        "X_train.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgdLkyyiuUfY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d433bab-1cd8-436a-8634-7da4dc1f46cc"
      },
      "source": [
        "X_test = np.transpose(X_test, axes=(0, 3, 1, 2))\n",
        "X_test.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu4HLk3t0Gk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Cifar10Classifier()\n",
        "model = model.cuda()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crvtSmiL4Lfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 50"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRoGovEQ4RKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "de5bf34f-a1a8-4b1d-9033-01291181ab95"
      },
      "source": [
        "train_loss, val_loss, train_acc, val_acc = model.fit(X_train, y_train, epochs, batch_size)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 finished in 5.87s. loss: 2.3028 - acc: 1269.93 - val loss: 2.3032 - val acc: 1189.60\n",
            "Epoch 1 finished in 5.75s. loss: 2.3028 - acc: 1288.49 - val loss: 2.3030 - val acc: 1189.60\n",
            "Epoch 2 finished in 5.73s. loss: 2.3027 - acc: 1273.60 - val loss: 2.3030 - val acc: 1189.60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-3b97d22980fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-06c8a5b33400>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, epochs, batch_size)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# train over dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mepoch_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_train_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_train_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-06c8a5b33400>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, X_train, y_train, batch_size)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mb_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5axkYcr74TlZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f8990afd-bf92-4fa7-ba4c-2b2c11f569f3"
      },
      "source": [
        "plt.imshow(X_train[6].astype(int))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f43e14feac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zHeP4dh84h0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "5c8ac3fa-6909-4f4e-84d6-0f9a9c0586cc"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 26.,  17.,  13., ...,  15.,  24.,  22.],\n",
              "        [ 20.,  13.,  13., ...,  19.,  21.,  29.],\n",
              "        [ 14.,  13.,  13., ...,  17.,  25.,  31.],\n",
              "        ...,\n",
              "        [ 90.,  34.,  28., ...,  23.,  16.,   9.],\n",
              "        [ 79.,  58.,  32., ...,  14.,  16.,  10.],\n",
              "        [128.,  58.,  25., ...,  13.,  12.,  13.]],\n",
              "\n",
              "       [[ 23.,  14.,   9., ...,  14.,  24.,  21.],\n",
              "        [ 17.,  10.,   9., ...,  17.,  20.,  29.],\n",
              "        [ 11.,  10.,   9., ...,  16.,  24.,  31.],\n",
              "        ...,\n",
              "        [109.,  64.,  54., ...,  20.,  13.,   6.],\n",
              "        [105.,  96.,  68., ...,  11.,  13.,   7.],\n",
              "        [157.,  93.,  60., ...,  10.,   9.,  10.]],\n",
              "\n",
              "       [[ 32.,  25.,  24., ...,  28.,  37.,  34.],\n",
              "        [ 26.,  22.,  24., ...,  35.,  35.,  39.],\n",
              "        [ 20.,  21.,  23., ...,  32.,  38.,  42.],\n",
              "        ...,\n",
              "        [137.,  95.,  90., ...,  37.,  30.,  23.],\n",
              "        [141., 139., 110., ...,  28.,  30.,  24.],\n",
              "        [196., 149., 106., ...,  27.,  26.,  27.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2UA4G9T9Id5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}