{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PytorchIntrudoction",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCQ4ZZahHJeqzn3Uk9MyIH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTIkT6BFWzJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import sklearn\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2w91ZrqW7mH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = fetch_openml('mnist_784')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWInqI7WXnfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = mnist.target"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43qhqupyXpk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = mnist.data.reshape(70000, 1, 28, 28)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M35lwjmXus0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=40)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkJLpygqYZz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        self.features = torch.nn.Sequential(                    # inp: B 1 28 28\n",
        "            torch.nn.Conv2d(1, 32, 3, stride=1, padding=0),     # B 32 26 26\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(32, 32, 3, stride=1, padding=0),    # B 32 24 24\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(2, stride=2, padding=0),         # B 32 12 12\n",
        "            torch.nn.Conv2d(32, 64, 3, stride=1, padding=0),    # B 64 10 10\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(64, 64, 3, stride=1, padding=0),    # B 64 8 8\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(2, stride=2, padding=0),         # B 64 4 4\n",
        "            torch.nn.Conv2d(64, 128, 3, stride=1, padding=0),   # B 128 2 2\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.decider = torch.nn.Sequential(\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(4 * 128, 128),                      # B 128\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 10)                            # B 10\n",
        "        )\n",
        "\n",
        "        self.log_prob_cal = torch.nn.LogSoftmax(dim=-1)\n",
        "    \n",
        "    def forward(self, b_x, b_y=None):\n",
        "        conv_features = self.features(b_x)\n",
        "        class_scores = self.decider(conv_features.flatten(1))\n",
        "        log_probs = self.log_prob_cal(class_scores)\n",
        "        loss = -1 * torch.mean(log_probs[torch.arange(b_x.shape[0]), b_y])\n",
        "        decision = torch.argmax(log_probs, dim=-1)\n",
        "        return decision, loss"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udcw6YGkgqtd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "c73b868b-c2b2-40d0-ac47-af79105303b0"
      },
      "source": [
        "model = MyModel()\n",
        "model.cuda()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (6): ReLU()\n",
              "    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (8): ReLU()\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (11): ReLU()\n",
              "  )\n",
              "  (decider): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              "  (log_prob_cal): LogSoftmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVWGCGxNhRGp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "c8a9d4d1-b8ba-416a-a697-eb6916104634"
      },
      "source": [
        "for n, v in model.named_parameters():\n",
        "    print(n)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features.0.weight\n",
            "features.0.bias\n",
            "features.2.weight\n",
            "features.2.bias\n",
            "features.5.weight\n",
            "features.5.bias\n",
            "features.7.weight\n",
            "features.7.bias\n",
            "features.10.weight\n",
            "features.10.bias\n",
            "decider.1.weight\n",
            "decider.1.bias\n",
            "decider.3.weight\n",
            "decider.3.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xBvKT_ykQCJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W8Ip21jjBMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "batch_x_placeholder = torch.zeros(size=[batch_size, 1, 28, 28], dtype=torch.float32, device=torch.device('cuda:0'))\n",
        "batch_y_placeholder = torch.zeros(size=[batch_size], dtype=torch.long, device=torch.device('cuda:0'))\n",
        "epochs = 10\n",
        "iters_per_epoch = 100\n",
        "train_loss = np.zeros((batch_size,))\n",
        "val_loss = np.zeros((batch_size,))\n",
        "train_acc = np.zeros((batch_size,))\n",
        "val_acc = np.zeros((batch_size,))"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiFOG6ssqKC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(filter(\n",
        "    lambda p: p.requires_grad, model.parameters()), lr=0.001\n",
        ")"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT_hpDk3kDfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpQzNWHmkkbe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "1604d696-e776-4408-ce42-e3fd939c850b"
      },
      "source": [
        "iters_per_epoch = int(np.ceil(1.0 * len(X_train) / batch_size))\n",
        "val_iters_per_epoch = int(np.ceil(1.0 * len(X_val) / batch_size))\n",
        "\n",
        "for e in range(epochs * 3, epochs * 4):\n",
        "    t_start = time()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # shuffling\n",
        "    indices = np.arange(len(X_train))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    epoch_loss = 0\n",
        "    tps = 0\n",
        "\n",
        "    # iterate over training set\n",
        "    for iter in range(iters_per_epoch):\n",
        "        batch_indices = indices[iter * batch_size: min(len(indices), (iter + 1) * batch_size)]\n",
        "\n",
        "        # reshape placeholder\n",
        "        if len(batch_indices) != len(batch_x_placeholder):\n",
        "            batch_x_placeholder.resize_([len(batch_indices), 1, 28, 28])\n",
        "            batch_y_placeholder.resize_([len(batch_indices)])\n",
        "\n",
        "        batch_x_placeholder.copy_(torch.Tensor(X_train[batch_indices, :, :, :]))\n",
        "        batch_y_placeholder.copy_(torch.Tensor(y_train[batch_indices].astype(int)))\n",
        "\n",
        "        b_decision, b_loss = model(batch_x_placeholder, batch_y_placeholder)\n",
        "        b_decision = b_decision.cpu().numpy()\n",
        "\n",
        "        epoch_loss += float(b_loss) / iters_per_epoch\n",
        "        tps += np.sum(y_train[batch_indices].astype(int) == b_decision)\n",
        "\n",
        "        b_loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "    epoch_train_accuracy = tps * 100.0 / len(X_train)\n",
        "    train_loss[e] = epoch_loss\n",
        "    train_acc[e] = epoch_train_accuracy\n",
        "\n",
        "    # validating over validation set\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        # shuffling\n",
        "        val_indices = np.arange(len(X_val))\n",
        "        np.random.shuffle(val_indices)\n",
        "\n",
        "        val_epoch_loss = 0\n",
        "        val_tps = 0\n",
        "\n",
        "        for iter in range(val_iters_per_epoch):\n",
        "            val_batch_indices = val_indices[iter * batch_size: min(len(val_indices), (iter + 1) * batch_size)]\n",
        "\n",
        "            # reshape placeholder\n",
        "            if len(val_batch_indices) != len(batch_x_placeholder):\n",
        "                batch_x_placeholder.resize_([len(val_batch_indices), 1, 28, 28])\n",
        "                batch_y_placeholder.resize_([len(val_batch_indices)])\n",
        "            \n",
        "            batch_x_placeholder.copy_(torch.Tensor(X_val[val_batch_indices]))\n",
        "            batch_y_placeholder.copy_(torch.Tensor(y_val[val_batch_indices].astype(int)))\n",
        "\n",
        "            b_decision, b_loss = model(batch_x_placeholder, batch_y_placeholder)\n",
        "            b_decision = b_decision.cpu().numpy()\n",
        "\n",
        "            val_epoch_loss += float(b_loss) / iters_per_epoch\n",
        "            val_tps += np.sum(y_val[val_batch_indices].astype(int) == b_decision)\n",
        "\n",
        "        epoch_val_accuracy = val_tps * 100.0 / len(X_val)\n",
        "        val_loss[e] = val_epoch_loss\n",
        "        val_acc[e] = epoch_val_accuracy\n",
        "\n",
        "    #saving model\n",
        "    torch.save({\n",
        "            'epoch': e,\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'epoch_loss': epoch_loss,\n",
        "            'epoch_train_accuracy': epoch_train_accuracy,\n",
        "            'val_epoch_loss': val_epoch_loss,\n",
        "            'epoch_val_accuracy': epoch_val_accuracy\n",
        "        }, f'MNIST/epoch_{e}_state.pt')\n",
        "\n",
        "    print(f'Epoch {e} finished in {time() - t_start:.2f}s. loss: {epoch_loss:.4f} - acc: {epoch_train_accuracy:.2f} - val loss: {val_epoch_loss:.4f} - val acc: {epoch_val_accuracy:.2f}')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 30 finished in 3.16s. loss: 0.0211 - acc: 99.45 - val loss: 0.0161 - val acc: 99.00\n",
            "Epoch 31 finished in 3.10s. loss: 0.0154 - acc: 99.61 - val loss: 0.0119 - val acc: 99.11\n",
            "Epoch 32 finished in 3.06s. loss: 0.0122 - acc: 99.67 - val loss: 0.0148 - val acc: 99.00\n",
            "Epoch 33 finished in 3.06s. loss: 0.0147 - acc: 99.63 - val loss: 0.0159 - val acc: 98.99\n",
            "Epoch 34 finished in 3.06s. loss: 0.0153 - acc: 99.63 - val loss: 0.0187 - val acc: 98.95\n",
            "Epoch 35 finished in 3.06s. loss: 0.0141 - acc: 99.66 - val loss: 0.0147 - val acc: 98.93\n",
            "Epoch 36 finished in 3.07s. loss: 0.0148 - acc: 99.65 - val loss: 0.0153 - val acc: 99.04\n",
            "Epoch 37 finished in 3.07s. loss: 0.0135 - acc: 99.69 - val loss: 0.0186 - val acc: 98.92\n",
            "Epoch 38 finished in 3.08s. loss: 0.0123 - acc: 99.67 - val loss: 0.0180 - val acc: 99.00\n",
            "Epoch 39 finished in 3.04s. loss: 0.0107 - acc: 99.72 - val loss: 0.0172 - val acc: 99.09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUUulcUvpEBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}